name: Databricks CI/CD - Feature Branch Support

on:
  push:
    branches:
      - master
      - feature/*
      - develop
  pull_request:
    branches: [master]

env:
  DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
  DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

jobs:
  # Job 1: Test and validate code quality
  test-and-validate:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install pyspark pytest black flake8
        pip install -e .

    - name: Code formatting check
      run: |
        black --check src/ || echo "Code formatting issues found"

    - name: Lint code
      run: |
        flake8 src/ --max-line-length=88 --ignore=E203,W503 || echo "Linting issues found"

    - name: Run unit tests (if any)
      run: |
        echo "Unit tests would run here"
        # pytest tests/unit/ -v

  # Job 2: Deploy to feature environment
  deploy-feature:
    runs-on: ubuntu-latest
    needs: test-and-validate
    if: startsWith(github.ref, 'refs/heads/feature/')

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - uses: databricks/setup-cli@main

    - name: Set branch-specific environment
      run: |
        # Create unique environment name based on branch
        BRANCH_NAME=$(echo ${{ github.ref_name }} | sed 's/feature\///' | sed 's/[^a-zA-Z0-9]/-/g')
        echo "FEATURE_ENV=feature-${BRANCH_NAME}" >> $GITHUB_ENV
        echo "Deploying to environment: feature-${BRANCH_NAME}"

    - name: Deploy to Feature Environment
      run: |
        # Destroy existing resources first, then deploy fresh
        databricks bundle destroy --target dev --var="environment_suffix=-${{ env.FEATURE_ENV }}" --auto-approve || true
        databricks bundle deploy --target dev --var="environment_suffix=-${{ env.FEATURE_ENV }}"
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

    - name: Run Feature Tests
      run: |
        echo "Running NYC Taxi pipeline..."
        # Get job ID from bundle and run directly
        JOB_ID=$(databricks jobs list --output json | jq -r '.jobs[] | select(.settings.name=="NYC Taxi Data Pipeline") | .job_id')
        if [ -n "$JOB_ID" ]; then
          echo "Found job ID: $JOB_ID"
          databricks jobs run-now --job-id $JOB_ID
          echo "Pipeline completed!"
        else
          echo "Job not found, skipping run"
        fi
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

  # Job 3: Deploy to main (only on master branch)
  deploy-main:
    runs-on: ubuntu-latest
    needs: test-and-validate
    if: github.ref == 'refs/heads/master'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - uses: databricks/setup-cli@main

    - name: Deploy to Main Environment
      run: |
        # Destroy existing resources first, then deploy fresh
        databricks bundle destroy --target dev --auto-approve || true
        databricks bundle deploy --target dev
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

    - name: Run Full Pipeline Test
      run: |
        echo "Running NYC Taxi pipeline..."
        databricks bundle run nyc_taxi_pipeline --target dev
        echo "Pipeline completed!"
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}